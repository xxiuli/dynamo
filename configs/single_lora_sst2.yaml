# single_lora_squad.yaml
# ========= 基本信息 =========
task_name: sst2
task_type: classification  # 可选: classification / nli / qa / summarization / ner
num_labels: 2
class_names: ['Negative', 'Positive']

# ========= 模型结构 =========
backbone_model: cardiffnlp/twitter-roberta-base-sentiment

lora:
  r: 8  # rank, 4 or 8 or 16
  alpha: 16 # output = W(x) + (alpha / r) * (A @ B)(x),一般是：8/16/32
  dropout: 0.1 # 通常设置为 0 ~ 0.1，任务简单时可设为 0；
  target_modules: ["query", "value"]  # 也可指定 attention 层子模块.attention 层包括："query", "value", "key", "output"

# ========= 训练参数 =========
train:
  seed: 42
  batch_size: 16
  learning_rate: 2e-4
  num_epochs: 5
  # num_epochs: 1
  max_seq_length: 128
  optimizer: adamw            # 可选: adamw, sgd, adafactor...
  lr_scheduler: linear        # 可选: linear, cosine, step
  warmup_ratio: 0.1           # 可选 warmup，用于 scheduler

# ========= 早停策略（可选）=========
early_stopping:
  enabled: true
  patience: 3
  monitor: val_acc    # best model
  mode: max           # val_loss是min，val_acc是max, val_f1是max

# ========= 路径 =========
data:
  train_file: ${DATA_ROOT}/single_lora_data/glue_sst2_train_07052025_1527.json
  val_file: ${DATA_ROOT}/single_lora_data/glue_sst2_validation_07052025_1527.json

output:
  save_dir: ${DRIVE_ROOT}/DynamoRouterCheckpoints/
  save_best_only: true
  monitor_metric: val_acc  # 自动对齐 early_stopping
  save_lora_adapter: true
  save_task_head: true
  log_dir: ${DRIVE_ROOT}/DynamoRouterLogs/

# ========= 调试专用 =========
# 调试时EPOCH可改为: num_epochs: 1
# 去COLAB训练时要把 skip_training: false, limit_batches: None 
debug:
  skip_evaluation: false    # 不跳评估，让模型至少走一次评估流程
  skip_training: false 
  limit_batches: null
  # skip_training: true       # 本地测试时用：跳过训练主循环，只测试evaluate和保存流程
  # limit_batches: 2          # 本地测试时用：：只取前2个batch进行evaluate（None表示不限制）
