# single_lora_squad.yaml
# ========= 基本信息 =========
task_name: squad
task_type: qa
num_labels: 2

# ========= 模型结构 =========
backbone_model: deepset/roberta-base-squad2 # （必须一致）

# LoRA 超参（必须一致）
lora:
  r: 8
  alpha: 16
  dropout: 0.1
  target_modules: ["query", "value"] # LoRA插入位置（必须一致）


# ========= 训练参数 =========
train:
  seed: 42
  batch_size: 8         # QA类任务可以适当减小batch
  learning_rate: 1e-5    # 通常QA比分类任务学习率更小
  num_epochs: 8
  # num_epochs: 1
  max_seq_length: 384    # QA一般较长 max_seq_length 要控制在统一范围（比如都不超过 512）
  optimizer: adamw
  # lr_scheduler: linear
  lr_scheduler: cosine
  warmup_ratio: 0.2
  label_smoothing: 0.1

# ========= 早停策略（可选）=========
early_stopping:
  enabled: true
  patience: 3
  monitor: val_exact_match  # best model
  mode: max          # val_loss是min，val_acc是max, val_f1是max

data:
  train_file: ${DATA_ROOT}/single_lora_data/squad_train__cleaned_file.jsonl
  val_file: ${DATA_ROOT}/single_lora_data/squad_val_cleaned_file.jsonl

output:
  save_dir: /${DRIVE_ROOT}/DynamoRouterCheckpoints/adapter_squad
  save_best_only: true
  monitor_metric: val_loss  # 自动对齐 early_stopping
  save_lora_adapter: true
  save_task_head: true
  log_dir: ${DRIVE_ROOT}/DynamoRouterLogs/adapter_squad

# ========= 调试专用 =========
# 调试时EPOCH可改为: num_epochs: 1
# 去COLAB训练时要把 skip_training: false, limit_batches: null
debug:
  skip_evaluation: false    # 不跳评估，让模型至少走一次评估流程
  skip_training: false 
  limit_batches: null
  # skip_training: true       # 本地测试时用：跳过训练主循环，只测试evaluate和保存流程
  # limit_batches: 2          # 本地测试时用：：只取前2个batch进行evaluate（None表示不限制）
