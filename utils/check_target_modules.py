from transformers import AutoModel
import torch.nn as nn

def list_lora_target_modules(model_name: str):
    print(f"\nğŸ” Checking LoRA target modules for: {model_name}")
    model = AutoModel.from_pretrained(model_name)
    
    # éå†æ‰€æœ‰å­æ¨¡å—
    candidate_modules = set()
    for name, module in model.named_modules():
        # ä»…ç­›é€‰å‡º Linear å±‚
        if isinstance(module, nn.Linear):
            short_name = name.split(".")[-1]
            candidate_modules.add(short_name)

    print("ğŸ§© Candidate LoRA target_modules:")
    for mod in sorted(candidate_modules):
        print(f"  - {mod}")

# ç¤ºä¾‹è°ƒç”¨
list_lora_target_modules("bert-base-uncased")
list_lora_target_modules("roberta-large")
list_lora_target_modules("google/pegasus-xsum")
