import argparse
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from peft import PeftModel, PeftConfig
import torch

def predict(model_dir, text):
    # Load tokenizer and PEFT config
    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    peft_config = PeftConfig.from_pretrained(model_dir)

    # Load base model
    base_model = AutoModelForSequenceClassification.from_pretrained(
        peft_config.base_model_name_or_path,  # è‡ªåŠ¨ä» adapter_config.json è¯»å–
        num_labels=2,   # For SST-2 
        local_files_only=True
    )

     # Load adapter weights
     # æŠŠä½ è®­ç»ƒå¥½çš„ LoRA adapter â€œæ³¨å…¥â€ åˆ° base model ä¸­ï¼Œç»„æˆæœ€ç»ˆçš„æ¨ç†æ¨¡å‹
    model = PeftModel.from_pretrained(base_model, model_dir)
    model.eval()

    #prepare input
    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)

    #run infernece
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        predicted_class = torch.argmax(logits, dim=-1).item()
    
    label_map = {0: "Negative", 1: "Positive"}
    print(f"\nâœ… Text: \"{text}\"\nğŸ§  Prediction: {label_map[predicted_class]}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_dir", type=str, required=True, help='Path to saved LoRA model')
    parser.add_argument("--text", type=str, required=True, help="Text to classify")
    args = parser.parse_args()

    predict(args.model_dir, args.text)